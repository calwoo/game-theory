{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../nash-equi/utils.py\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def support(sigma, tol=1e-10):\n",
    "    \"\"\"\n",
    "    get support of a strategy\n",
    "    \"\"\"\n",
    "    sigma = np.array(sigma)\n",
    "    return np.where(sigma > tol)[0]\n",
    "\n",
    "def is_best_response(A, sigma_A, sigma_B):\n",
    "    \"\"\"\n",
    "    check if a given strategy sigma_A is the best response to opponent\n",
    "    strategy sigma_B\n",
    "    \"\"\"\n",
    "    # set as np.arrays\n",
    "    sigma_A, sigma_B = np.array(sigma_A), np.array(sigma_B)\n",
    "    spt = support(sigma_A)\n",
    "    best = True\n",
    "    Ay = A @ sigma_B\n",
    "    max_Ay = max(Ay)\n",
    "    for i in spt:\n",
    "        if Ay[i] != max_Ay:\n",
    "            best = False\n",
    "    return best\n",
    "\n",
    "def indifference(payoff, support_u, support_v):\n",
    "    \"\"\"\n",
    "    compute indifference matrix for a given support.\n",
    "    for reference, just check out \"algorithmic game theory\"\n",
    "    by nisan et. al\n",
    "    \"\"\"\n",
    "    n = len(payoff[0])\n",
    "    M = np.zeros((len(support_u) + n - len(support_v), n), dtype=np.float64)\n",
    "    # condition 1: best response condition for given support\n",
    "    for i in range(len(support_u) - 1):\n",
    "        M[i] = payoff[support_u[i]] - payoff[support_u[i+1]]\n",
    "    # condition 2: ensure support is in S(v)\n",
    "    complement_Sv = [j for j in range(n) if j not in support_v]\n",
    "    for k, i in enumerate(range(len(support_u) - 1, len(support_u) + n - len(support_v) - 1)):\n",
    "        M[i][complement_Sv[k]] = 1\n",
    "    # condition 3: last row is all 1's to ensure solution is a probability vector\n",
    "    M[-1] = np.ones(n)\n",
    "    return M\n",
    "\n",
    "def equilibrium_candidate(payoff, support_u, support_v):\n",
    "    \"\"\"\n",
    "    using indifference, compute a candidate for the nash equilibrium\n",
    "    given fixed supports\n",
    "    \"\"\"\n",
    "    M = indifference(payoff, support_u, support_v)\n",
    "    b = np.zeros(M.shape[1])\n",
    "    b[-1] = 1\n",
    "    # return np.linalg.inv(M) @ b\n",
    "    return np.linalg.solve(M, b)\n",
    "\n",
    "def get_powerset(n):\n",
    "    \"\"\"\n",
    "    get powerset of n using itertools\n",
    "    \"\"\"\n",
    "    return itertools.chain.from_iterable(\n",
    "        itertools.combinations(range(n), r) for r in range(n + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../nash-equi/game.py\n",
    "\"\"\"\n",
    "stupid implementation of a normal form game, and eventual\n",
    "computations of nash equilibria\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class game:\n",
    "    \"\"\"\n",
    "    2 player normal form game\n",
    "    \"\"\"\n",
    "    def __init__(self, payoff_A, payoff_B=None):\n",
    "        self.payoff_A = np.array(payoff_A)\n",
    "        if payoff_B is None:\n",
    "            # zero-sum game\n",
    "            self.payoff_B = -self.payoff_A\n",
    "        else:\n",
    "            self.payoff_B = np.array(payoff_B)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"player 1 payoff:\\n\" + str(self.payoff_A) + \"\\n\\n\" + \\\n",
    "               \"player 2 payoff:\\n\" + str(self.payoff_B)\n",
    "    \n",
    "    def payoff(self, sigma_1, sigma_2):\n",
    "        expected_payoff_1 = sigma_1.T @ self.payoff_A @ sigma_2\n",
    "        expected_payoff_2 = sigma_1.T @ self.payoff_B @ sigma_2\n",
    "        return np.array([expected_payoff_1, expected_payoff_2])\n",
    "\n",
    "    def equilibria(self):\n",
    "        \"\"\"\n",
    "        find all Nash equilibria of 2-player normal form game via \n",
    "        support enumeration.\n",
    "        \"\"\"\n",
    "        n, m = self.payoff_A.shape\n",
    "        # create supports\n",
    "        for support_u in (s for s in get_powerset(n) if len(s) > 0):\n",
    "            for support_v in (s for s in get_powerset(m) if len(s) == len(support_u)):\n",
    "                # get candidate for nash equilibrium\n",
    "                try:\n",
    "                    candidate_A = equilibrium_candidate(self.payoff_A, support_u, support_v)\n",
    "                    candidate_B = equilibrium_candidate(self.payoff_B.T, support_v, support_u)\n",
    "                    # check if best response to one another\n",
    "                    if is_best_response(self.payoff_B.T, candidate_A, candidate_B) and \\\n",
    "                        is_best_response(self.payoff_A, candidate_B, candidate_A):\n",
    "                            return [candidate_A, candidate_B]\n",
    "                except:\n",
    "                    continue\n",
    "        return \"no Nash equilibria found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "player 1 payoff:\n",
       "[[ 1  1 -1]\n",
       " [ 2 -1  0]]\n",
       "\n",
       "player 2 payoff:\n",
       "[[ 0.5 -1.  -0.5]\n",
       " [-1.   3.   2. ]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = [[1, 1, -1], [2, -1, 0]]\n",
    "B = [[1/2, -1, -1/2], [-1, 3, 2]]\n",
    "\n",
    "g = game(A, B)\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.        ,  0.33333333,  0.66666667]),\n",
       " array([0.66666667, 0.33333333])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.equilibria()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "player 1 payoff:\n",
       "[[ 1 -1]\n",
       " [-1  1]]\n",
       "\n",
       "player 2 payoff:\n",
       "[[-1  1]\n",
       " [ 1 -1]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coin flipping\n",
    "A = [[1, -1], [-1, 1]]\n",
    "B = [[-1, 1], [1, -1]]\n",
    "\n",
    "g = game(A, B)\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.5, 0.5]), array([0.5, 0.5])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.equilibria()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "player 1 payoff:\n",
       "[[ 0 -1  1]\n",
       " [ 1  0 -1]\n",
       " [-1  1  0]]\n",
       "\n",
       "player 2 payoff:\n",
       "[[ 0  1 -1]\n",
       " [-1  0  1]\n",
       " [ 1 -1  0]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rock paper scissors\n",
    "A = [[0, -1, 1], [1, 0, -1], [-1, 1, 0]]\n",
    "\n",
    "rps = game(A)\n",
    "rps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.33333333, 0.33333333, 0.33333333]),\n",
       " array([0.33333333, 0.33333333, 0.33333333])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rps.equilibria()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
